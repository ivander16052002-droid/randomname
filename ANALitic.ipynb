# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
from sklearn.metrics import mean_squared_error
from dateutil.relativedelta import relativedelta
import logging
import os

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

TARGET = 'Продажи'
FORECAST_MONTHS = 18


# ==== 1. Загрузка данных ====
def load_data(sales_path, stock_path, ms_path, dist_index_path=None, weather_path=None,
              discounts_path=None, longterm_avg_path=None):
    logging.info("Шаг 1: Загружаем данные...")
    try:
        sales = pd.read_csv(sales_path, encoding='utf-8')
        stock = pd.read_csv(stock_path, encoding='utf-8')
        ms = pd.read_csv(ms_path, encoding='utf-8')
    except FileNotFoundError as e:
        logging.error(f"Не найден файл: {e}")
        return None, None, None, None, None, None, None

    dist = pd.read_csv(dist_index_path, encoding='utf-8') if dist_index_path and os.path.exists(dist_index_path) else None
    weather = pd.read_csv(weather_path, encoding='utf-8') if weather_path and os.path.exists(weather_path) else None
    discounts = pd.read_csv(discounts_path, encoding='utf-8') if discounts_path and os.path.exists(discounts_path) else None
    longterm = pd.read_csv(longterm_avg_path, encoding='utf-8') if longterm_avg_path and os.path.exists(longterm_avg_path) else None

    logging.info("Данные успешно загружены.")
    return sales, stock, ms, dist, weather, discounts, longterm


# ==== 2. Предобработка ====
def preprocess_dates(df, year_col='Год', month_col='Месяц'):
    df[year_col] = df[year_col].astype(int)
    df[month_col] = df[month_col].astype(int)
    df['Дата'] = pd.to_datetime(dict(year=df[year_col], month=df[month_col], day=1))
    return df


def parse_city_index(df, col='Город/Индекс'):
    def _parse(v):
        if pd.isna(v):
            return (None, None)
        s = str(v).strip()
        if s.isdigit():
            return (None, s)
        else:
            return (s, None)
    parsed = df[col].apply(lambda x: pd.Series(_parse(x), index=['Город', 'Индекс']))
    df = pd.concat([df.drop(columns=[col]), parsed], axis=1)
    return df


# ==== 3. Объединение ====
def merge_all(sales, stock, ms, dist=None, weather=None, discounts=None):
    logging.info("Шаг 2: Объединяем таблицы...")
    df = sales.merge(stock, on=['Сеть', 'ID_Контрагента', 'Год', 'Месяц'], how='left')
    df = df.merge(ms, on=['Сеть', 'Год', 'Месяц'], how='left')
    if dist is not None:
        df = df.merge(dist, on=['ID_Контрагента','Год','Месяц'], how='left')
    if weather is not None:
        df = df.merge(weather, on=['Год','Месяц'], how='left')
    if discounts is not None:
        df = df.merge(discounts, on=['Сеть','ID_Контрагента','Год','Месяц'], how='left')
    df = preprocess_dates(df)
    logging.info(f"Объединённый датафрейм: {df.shape}")
    return df


# ==== 4. Сетка ====
def create_full_grid(df, forecast_months=FORECAST_MONTHS):
    logging.info("Шаг 3: Создаём полную временную сетку...")
    start = df['Дата'].min()
    last_historical = df['Дата'].max()
    end = (last_historical + relativedelta(months=forecast_months)).replace(day=1)

    combos = df[['Сеть','ID_Контрагента','Город','Индекс']].drop_duplicates().reset_index(drop=True)
    all_months = pd.date_range(start=start, end=end, freq='MS')

    grid = pd.MultiIndex.from_product([combos.index, all_months], names=['comb_idx','Дата']).to_frame(index=False)
    full = grid.merge(combos, left_on='comb_idx', right_index=True).drop(columns=['comb_idx'])
    full = full.merge(df, on=['Сеть','ID_Контрагента','Город','Индекс','Дата'], how='left')

    full['Год'] = full['Дата'].dt.year
    full['Месяц'] = full['Дата'].dt.month
    logging.info(f"Сетка готова: {full.shape}")
    return full


# ==== 5. Чистка и фичи ====
def clean_and_features(df):
    logging.info("Шаг 4: Очистка и добавление фич...")
    # Если в исторических данных есть NaN по Продажи — оставляем NaN (чтобы отличать "нет наблюдения" от 0),
    # но для обучающей части обычно нужна реальная метка. В твоей версии заменяли на 0 — оставил замену на 0,
    # как в оригинале, но можно менять по желанию.
    df[TARGET] = df[TARGET].fillna(0)
    for col in ['Остатки в рынке','УСТМ','НТЗ','ТМА','discount_pct']:
        if col in df.columns:
            df[col] = df[col].fillna(0)
    df['Сеть'] = df['Сеть'].fillna('Без сети')
    df['Город'] = df['Город'].fillna('UNKNOWN')
    df['Индекс'] = df['Индекс'].fillna('UNKNOWN')
    df['is_active'] = ((df[TARGET] > 0) | (df.get('Остатки в рынке', 0) > 0)).astype(int)
    return df


# ==== 6. Лаги (до 12) ====
def add_lags(df, max_lag=12, rollings=[3, 6, 12]):
    logging.info(f"Шаг 5: Добавляем лаги (до {max_lag} месяцев) и скользящие средние...")
    df = df.sort_values(['ID_Контрагента', 'Дата']).copy()

    # создаём лаги
    for lag in range(1, max_lag + 1):
        col = f'{TARGET}_lag_{lag}'
        df[col] = df.groupby('ID_Контрагента')[TARGET].shift(lag)

    # скользящие средние (по предыдущим значениям)
    for w in rollings:
        col = f'{TARGET}_rollmean_{w}'
        df[col] = df.groupby('ID_Контрагента')[TARGET].shift(1).rolling(window=w, min_periods=1).mean().reset_index(level=0, drop=True)

    # Заменяем NaN в фичах на 0 (модель не любит NaN)
    lag_cols = [f'{TARGET}_lag_{lag}' for lag in range(1, max_lag + 1)]
    roll_cols = [f'{TARGET}_rollmean_{w}' for w in rollings]
    for c in lag_cols + roll_cols:
        if c in df.columns:
            df[c] = df[c].fillna(0)

    return df


# ==== 7. Обучение: фиксированные splits и финальная модель ====
def train_and_evaluate(df, features, train_end, val_start, val_end, test_start, test_end, last_hist_date):
    logging.info("Шаг 6: Обучаем модель на Train и оцениваем на Val/Test...")

    # Маски (включительно)
    train_mask = df['Дата'] <= pd.Timestamp(train_end)
    val_mask = (df['Дата'] >= pd.Timestamp(val_start)) & (df['Дата'] <= pd.Timestamp(val_end))
    test_mask = (df['Дата'] >= pd.Timestamp(test_start)) & (df['Дата'] <= pd.Timestamp(test_end))

    X_train, y_train = df.loc[train_mask, features], df.loc[train_mask, TARGET]
    X_val, y_val = df.loc[val_mask, features], df.loc[val_mask, TARGET]
    X_test, y_test = df.loc[test_mask, features], df.loc[test_mask, TARGET]

    # Обучаем модель для оценки
    eval_model = xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.05, n_jobs=4)
    eval_model.fit(X_train, y_train)

    preds_val = eval_model.predict(X_val) if len(X_val) > 0 else np.array([])
    preds_test = eval_model.predict(X_test) if len(X_test) > 0 else np.array([])

    rmse_val = mean_squared_error(y_val, preds_val, squared=False) if len(preds_val) > 0 else None
    rmse_test = mean_squared_error(y_test, preds_test, squared=False) if len(preds_test) > 0 else None

    logging.info(f"RMSE Validation ({val_start} — {val_end}): {rmse_val if rmse_val is not None else 'no data'}")
    logging.info(f"RMSE Test ({test_start} — {test_end}): {rmse_test if rmse_test is not None else 'no data'}")

    # Финальная модель для прогноза: обучаем на всех исторических данных до last_hist_date (включительно)
    final_mask = df['Дата'] <= pd.Timestamp(last_hist_date)
    X_final, y_final = df.loc[final_mask, features], df.loc[final_mask, TARGET]
    final_model = xgb.XGBRegressor(n_estimators=300, max_depth=6, learning_rate=0.05, n_jobs=4)
    final_model.fit(X_final, y_final)
    logging.info("Финальная модель обучена на всех исторических данных для прогноза.")

    return eval_model, final_model, rmse_val, rmse_test


# ==== 8. Прогноз с динамическим обновлением лагов ====
def forecast_with_dynamic_lags(df, model, features, start_date, months=FORECAST_MONTHS, max_lag=12, rollings=[3, 6, 12]):
    logging.info("Шаг 7: Прогнозируем с обновлением лагов...")
    forecasts = []

    # Убедимся, что лаги уже добавлены
    df = add_lags(df, max_lag=max_lag, rollings=rollings)

    for step in range(months):
        cur_month = (start_date + relativedelta(months=step)).replace(day=1)
        logging.info(f"Прогноз для месяца: {cur_month.strftime('%Y-%m')}")

        idx = df['Дата'] == cur_month
        if idx.sum() == 0:
            logging.warning(f"Нет строк для месяца {cur_month.strftime('%Y-%m')} в сетке — пропускаем.")
            continue

        X = df.loc[idx, features].fillna(0)
        preds = model.predict(X)
        # Записываем предсказания в основной df (они будут учитываться при пересчёте лагов)
        df.loc[idx, TARGET] = preds
        forecasts.append(df.loc[idx, ['Сеть', 'ID_Контрагента', 'Дата', TARGET]])

        # Пересчитываем лаги и скользящие, чтобы учесть новые предсказания для следующих шагов
        df = add_lags(df, max_lag=max_lag, rollings=rollings)

    if len(forecasts) == 0:
        return pd.DataFrame(columns=['Сеть', 'ID_Контрагента', 'Дата', TARGET])
    return pd.concat(forecasts)


# ==== 9. Основной пайплайн ====
def pipeline(sales_path, stock_path, ms_path,
             dist_path=None, weather_path=None, discounts_path=None, longterm_path=None):
    sales, stock, ms, dist, weather, discounts, longterm = load_data(
        sales_path, stock_path, ms_path, dist_path, weather_path, discounts_path, longterm_path
    )

    if sales is None:
        return

    sales = preprocess_dates(parse_city_index(sales))
    stock = preprocess_dates(stock)
    ms = preprocess_dates(ms)
    if dist is not None:
        dist = preprocess_dates(dist)
    if weather is not None:
        weather = preprocess_dates(weather)
    if discounts is not None:
        discounts = preprocess_dates(discounts)

    df = merge_all(sales, stock, ms, dist, weather, discounts)
    df = create_full_grid(df)
    df = clean_and_features(df)

    # Добавляем лаги до 12 сразу — далее они будут пересчитываться в цикле прогноза
    df = add_lags(df, max_lag=12, rollings=[3, 6, 12])

    # Список признаков: исключаем служебные колонки
    exclude_cols = ['Сеть', 'Город', 'Индекс', 'Дата', TARGET, 'ID_Контрагента', 'Год', 'Месяц']
    features = [c for c in df.columns if c not in exclude_cols]

    last_hist_date = sales['Дата'].max()

    # Фиксированные границы (как просил)
    train_end = '2024-12-31'
    val_start = '2025-01-01'
    val_end = '2025-07-31'
    test_start = '2025-08-01'
    test_end = '2026-12-31'

    # Обучаем и получаем финальную модель
    eval_model, final_model, rmse_val, rmse_test = train_and_evaluate(
        df, features, train_end, val_start, val_end, test_start, test_end, last_hist_date
    )

    # Делаем прогноз пошагово, используя final_model
    forecast_df = forecast_with_dynamic_lags(
        df.copy(), final_model, features,
        start_date=(last_hist_date + relativedelta(months=1)).replace(day=1),
        months=FORECAST_MONTHS,
        max_lag=12,
        rollings=[3, 6, 12]
    )

    agg_forecast = forecast_df.groupby('Дата')[TARGET].sum().reset_index()

    # Сохраняем
    forecast_df.to_csv('forecast_by_pharmacy.csv', index=False)
    agg_forecast.to_csv('forecast_agg_product.csv', index=False)
    joblib.dump(final_model, 'xgb_final_model.joblib')

    logging.info("Готово! Прогноз и модель сохранены.")
    return final_model, forecast_df, agg_forecast


if __name__ == '__main__':
    pipeline(
        sales_path='Продажи.csv',
        stock_path='Остатки.csv',
        ms_path='МС.csv',
        dist_path='index_by_pharmacy.csv',
        weather_path='weather.csv',
        discounts_path='discounts.csv',
        longterm_path='10y_monthly_avg.csv'
    )
