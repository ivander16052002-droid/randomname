import pandas as pd
import numpy as np
import xgboost as xgb
import joblib
from sklearn.metrics import mean_squared_error
from dateutil.relativedelta import relativedelta
import logging
import os

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s:%(message)s')

TARGET = 'Продажи'
FORECAST_MONTHS = 18
FORCE_START = pd.Timestamp('2025-08-01')  # требование: старт с августа 2025
STOP_THRESHOLD_MONTHS = 3  # если с последней продажи прошло >3 месяцев — прогноз=0


# ==== 1. Загрузка данных ====
def load_data(sales_path, stock_path, ms_path, dist_index_path=None, weather_path=None,
              discounts_path=None, longterm_avg_path=None):
    logging.info("Шаг 1: Загружаем данные...")
    try:
        sales = pd.read_csv(sales_path, encoding='utf-8')
        stock = pd.read_csv(stock_path, encoding='utf-8')
        ms = pd.read_csv(ms_path, encoding='utf-8')
    except FileNotFoundError as e:
        logging.error(f"Не найден файл: {e}")
        return None, None, None, None, None, None, None

    dist = pd.read_csv(dist_index_path, encoding='utf-8') if dist_index_path and os.path.exists(dist_index_path) else None
    weather = pd.read_csv(weather_path, encoding='utf-8') if weather_path and os.path.exists(weather_path) else None
    discounts = pd.read_csv(discounts_path, encoding='utf-8') if discounts_path and os.path.exists(discounts_path) else None
    longterm = pd.read_csv(longterm_avg_path, encoding='utf-8') if longterm_avg_path and os.path.exists(longterm_avg_path) else None

    logging.info("Данные успешно загружены.")
    return sales, stock, ms, dist, weather, discounts, longterm


# ==== 2. Предобработка ====
def preprocess_dates(df, year_col='Год', month_col='Месяц'):
    # Приводим типы и строим единую дату (первое число месяца)
    df[year_col] = pd.to_numeric(df[year_col], errors='coerce').astype('Int64')
    df[month_col] = pd.to_numeric(df[month_col], errors='coerce').astype('Int64')
    df = df.dropna(subset=[year_col, month_col]).copy()
    df[year_col] = df[year_col].astype(int)
    df[month_col] = df[month_col].astype(int)
    df['Дата'] = pd.to_datetime(dict(year=df[year_col], month=df[month_col], day=1))
    return df


def parse_city_index(df, col='Город/Индекс'):
    def _parse(v):
        if pd.isna(v):
            return (None, None)
        s = str(v).strip()
        if s.isdigit():
            return (None, s)
        else:
            return (s, None)
    if col in df.columns:
        parsed = df[col].apply(lambda x: pd.Series(_parse(x), index=['Город', 'Индекс']))
        df = pd.concat([df.drop(columns=[col]), parsed], axis=1)
    if 'Город' not in df.columns:
        df['Город'] = np.nan
    if 'Индекс' not in df.columns:
        df['Индекс'] = np.nan
    return df


# ==== 3. Объединение ====
def drop_date_if_exists(dfi):
    # Чтобы избежать ValueError по Дата_x/Дата_y при слиянии
    return dfi.drop(columns=[c for c in dfi.columns if c.strip().lower() == 'дата'], errors='ignore')


def merge_all(sales, stock, ms, dist=None, weather=None, discounts=None):
    logging.info("Шаг 2: Объединяем таблицы...")

# Перед merge удалим 'Дата' у правых таблиц, объединяем по ключам без 'Дата'
    stock = drop_date_if_exists(stock)
    ms = drop_date_if_exists(ms)
    if dist is not None:
        dist = drop_date_if_exists(dist)
    if weather is not None:
        weather = drop_date_if_exists(weather)
    if discounts is not None:
        discounts = drop_date_if_exists(discounts)

    df = sales.merge(stock, on=['Сеть', 'ID_Контрагента', 'Год', 'Месяц'], how='left')
    df = df.merge(ms, on=['Сеть', 'Год', 'Месяц'], how='left')
    if dist is not None:
        df = df.merge(dist, on=['ID_Контрагента','Год','Месяц'], how='left')
    if weather is not None:
        df = df.merge(weather, on=['Год','Месяц'], how='left')
    if discounts is not None:
        df = df.merge(discounts, on=['Сеть','ID_Контрагента','Год','Месяц'], how='left')

    # Создаём единую дату ТОЛЬКО здесь
    df = preprocess_dates(df)
    logging.info(f"Объединённый датафрейм: {df.shape}")
    return df


# ==== 4. Сетка ====
def create_full_grid(df, forecast_months=FORECAST_MONTHS, force_start=FORCE_START):
    logging.info("Шаг 3: Создаём полную временную сетку...")
    start = df['Дата'].min()
    last_historical = df['Дата'].max()

    # Горизонт строим до max(last_historical + forecast_months, force_start + forecast_months - 1)
    end_candidate_1 = (last_historical + relativedelta(months=forecast_months)).replace(day=1)
    end_candidate_2 = (force_start + relativedelta(months=forecast_months-1)).replace(day=1)
    end = max(end_candidate_1, end_candidate_2)

    combos = df[['Сеть','ID_Контрагента','Город','Индекс']].drop_duplicates().reset_index(drop=True)
    all_months = pd.date_range(start=start, end=end, freq='MS')

    grid = pd.MultiIndex.from_product([combos.index, all_months], names=['comb_idx','Дата']).to_frame(index=False)
    full = grid.merge(combos, left_on='comb_idx', right_index=True).drop(columns=['comb_idx'])
    full = full.merge(df, on=['Сеть','ID_Контрагента','Город','Индекс','Дата'], how='left')

    full['Год'] = full['Дата'].dt.year
    full['Месяц'] = full['Дата'].dt.month
    logging.info(f"Сетка готова: {full.shape}")
    return full


# ==== 5. Чистка и фичи ====
def clean_and_features(df):
    logging.info("Шаг 4: Очистка и добавление фич...")
    df[TARGET] = df[TARGET].fillna(0)
    for col in ['Остатки в рынке','УСТМ','НТЗ','ТМА','discount_pct','МС','Погода','Погода_индекс']:
        if col in df.columns:
            df[col] = df[col].fillna(0)
    df['Сеть'] = df['Сеть'].fillna('Без сети')
    df['Город'] = df['Город'].fillna('UNKNOWN')
    df['Индекс'] = df['Индекс'].fillna('UNKNOWN')
    df['is_active'] = ((df[TARGET] > 0) | (df.get('Остатки в рынке', 0) > 0)).astype(int)

    # Логарифм и первая разность по лог-продажам
    df['log_sales'] = np.log1p(df[TARGET])
    df['log_sales_lag1'] = df.groupby('ID_Контрагента')['log_sales'].shift(1)
    df['log_diff_1'] = df['log_sales'] - df['log_sales_lag1']
    df['log_diff_1'] = df['log_diff_1'].fillna(0)

    return df


# ==== 6. Лаги (до 12) ====
def add_lags(df, max_lag=12, rollings=[3, 6, 12]):
    logging.info(f"Шаг 5: Добавляем лаги (до {max_lag} месяцев) и скользящие средние...")
    df = df.sort_values(['ID_Контрагента', 'Дата']).copy()

    # создаём лаги по исходным продажам
    for lag in range(1, max_lag + 1):
        col = f'{TARGET}_lag_{lag}'
        df[col] = df.groupby('ID_Контрагента')[TARGET].shift(lag)

    # лаги по лог-продажам (удобны для градиентов)
    for lag in range(1, max_lag + 1):
        col = f'log_sales_lag_{lag}'
        df[col] = df.groupby('ID_Контрагента')['log_sales'].shift(lag)

    # скользящие средние (по предыдущим значениям)
    for w in rollings:
        col = f'{TARGET}_rollmean_{w}'
        df[col] = (
            df.groupby('ID_Контрагента')[TARGET]
              .shift(1)
              .rolling(window=w, min_periods=1)
              .mean()
              .reset_index(level=0, drop=True)
        )

# Заменяем NaN в фичах на 0 (модель не любит NaN)
    lag_cols = [f'{TARGET}_lag_{lag}' for lag in range(1, max_lag + 1)]
    lag_cols += [f'log_sales_lag_{lag}' for lag in range(1, max_lag + 1)]
    roll_cols = [f'{TARGET}_rollmean_{w}' for w in rollings]
    for c in lag_cols + roll_cols + ['log_sales_lag1', 'log_diff_1']:
        if c in df.columns:
            df[c] = df[c].fillna(0)

    return df


# ==== 7. Обучение: splits и финальная модель ====
def train_and_evaluate(df, features, train_end, val_start, val_end, test_start, test_end, last_hist_date):
    logging.info("Шаг 6: Обучаем модель на Train и оцениваем на Val/Test (в лог-шкале)...")

    # Маски (включительно)
    train_mask = df['Дата'] <= pd.Timestamp(train_end)
    val_mask = (df['Дата'] >= pd.Timestamp(val_start)) & (df['Дата'] <= pd.Timestamp(val_end))
    test_mask = (df['Дата'] >= pd.Timestamp(test_start)) & (df['Дата'] <= pd.Timestamp(test_end))

    X_train, y_train = df.loc[train_mask, features], np.log1p(df.loc[train_mask, TARGET])
    X_val, y_val = df.loc[val_mask, features], np.log1p(df.loc[val_mask, TARGET])
    X_test, y_test = df.loc[test_mask, features], np.log1p(df.loc[test_mask, TARGET])

    eval_model = xgb.XGBRegressor(n_estimators=400, max_depth=6, learning_rate=0.05, n_jobs=4, subsample=0.9, colsample_bytree=0.9, objective='reg:squarederror')
    eval_model.fit(X_train, y_train)

    preds_val_log = eval_model.predict(X_val) if len(X_val) > 0 else np.array([])
    preds_test_log = eval_model.predict(X_test) if len(X_test) > 0 else np.array([])

    # RMSE в оригинальной шкале
    rmse_val = mean_squared_error(np.expm1(y_val), np.expm1(preds_val_log), squared=False) if len(preds_val_log) > 0 else None
    rmse_test = mean_squared_error(np.expm1(y_test), np.expm1(preds_test_log), squared=False) if len(preds_test_log) > 0 else None

    logging.info(f"RMSE Validation ({val_start} — {val_end}): {rmse_val if rmse_val is not None else 'no data'}")
    logging.info(f"RMSE Test ({test_start} — {test_end}): {rmse_test if rmse_test is not None else 'no data'}")

    # Финальная модель для прогноза: обучаем на всех исторических данных до last_hist_date (включительно)
    final_mask = df['Дата'] <= pd.Timestamp(last_hist_date)
    X_final, y_final = df.loc[final_mask, features], np.log1p(df.loc[final_mask, TARGET])
    final_model = xgb.XGBRegressor(n_estimators=400, max_depth=6, learning_rate=0.05, n_jobs=4, subsample=0.9, colsample_bytree=0.9, objective='reg:squarederror')
    final_model.fit(X_final, y_final)
    logging.info("Финальная модель обучена на всех исторических данных для прогноза (лог-шкала).")

    return eval_model, final_model, rmse_val, rmse_test


# ==== 8. Вспомогательное: последняя дата продажи по контрагенту ====
def compute_last_real_sale_date(df, last_hist_date):
    hist = df[(df['Дата'] <= last_hist_date) & (df[TARGET] > 0)][['ID_Контрагента','Дата']]
    last_sale = hist.groupby('ID_Контрагента')['Дата'].max().rename('last_sale_date')
    return last_sale


# ==== 9. Прогноз с динамическими лагами и правилами остановки ====

def months_diff(a: pd.Timestamp, b: pd.Timestamp) -> int:
    return (a.year - b.year) * 12 + (a.month - b.month)


def forecast_with_dynamic_lags(df, model, features, start_date, months=FORECAST_MONTHS, max_lag=12, rollings=[3, 6, 12], last_sale_s: pd.Series = None):
    logging.info("Шаг 7: Прогнозируем с обновлением лагов и ограничением >3 мес без продаж...")
    forecasts = []

    # Убедимся, что лаги уже добавлены
    df = add_lags(df, max_lag=max_lag, rollings=rollings)

    # Добавим последнюю дату реальной продажи для всех строк (для удобства векторизации)
    if last_sale_s is not None:
        df = df.merge(last_sale_s.rename('last_sale_date'), on='ID_Контрагента', how='left')

    for step in range(months):
        cur_month = (start_date + relativedelta(months=step)).replace(day=1)
        logging.info(f"Прогноз для месяца: {cur_month.strftime('%Y-%m')}")

idx = df['Дата'] == cur_month
        if idx.sum() == 0:
            logging.warning(f"Нет строк для месяца {cur_month.strftime('%Y-%m')} в сетке — пропускаем.")
            continue

        X = df.loc[idx, features].fillna(0)
        preds_log = model.predict(X)
        preds = np.expm1(preds_log)

        # Правило остановки: если с последней РЕАЛЬНОЙ продажи прошло > 3 мес — 0
        if 'last_sale_date' in df.columns:
            last_sale = df.loc[idx, 'last_sale_date']
            # NaT трактуем как очень давно
            months_since = last_sale.apply(lambda d: 10_000 if pd.isna(d) else months_diff(cur_month, d))
            mask_stop = months_since > STOP_THRESHOLD_MONTHS
            preds = np.where(mask_stop.values, 0.0, preds)

        # Округление до целых и клип до неотрицательных
        preds = np.maximum(0, np.round(preds))

        # Записываем предсказания в основной df (они будут учитываться при пересчёте лагов)
        df.loc[idx, TARGET] = preds
        df.loc[idx, 'log_sales'] = np.log1p(df.loc[idx, TARGET])
        forecasts.append(df.loc[idx, ['Сеть', 'ID_Контрагента', 'Дата', TARGET]])

        # Пересчитываем лаги и скользящие, чтобы учесть новые предсказания для следующих шагов
        df = add_lags(df, max_lag=max_lag, rollings=rollings)

    if len(forecasts) == 0:
        return pd.DataFrame(columns=['Сеть', 'ID_Контрагента', 'Дата', TARGET])
    return pd.concat(forecasts)

# ==== 10. Основной пайплайн ====
def pipeline(sales_path, stock_path, ms_path,
             dist_path=None, weather_path=None, discounts_path=None, longterm_path=None):
    sales, stock, ms, dist, weather, discounts, longterm = load_data(
        sales_path, stock_path, ms_path, dist_path, weather_path, discounts_path, longterm_path
    )

    if sales is None:
        return

    sales = preprocess_dates(parse_city_index(sales))
    stock = preprocess_dates(stock)
    ms = preprocess_dates(ms)
    if dist is not None:
        dist = preprocess_dates(dist)
    if weather is not None:
        weather = preprocess_dates(weather)
    if discounts is not None:
        discounts = preprocess_dates(discounts)

    df = merge_all(sales, stock, ms, dist, weather, discounts)
    df = create_full_grid(df, forecast_months=FORECAST_MONTHS, force_start=FORCE_START)
    df = clean_and_features(df)

    # Добавляем лаги до 12 сразу — далее они будут пересчитываться в цикле прогноза
    df = add_lags(df, max_lag=12, rollings=[3, 6, 12])

    # Список признаков: исключаем служебные колонки
    exclude_cols = ['Сеть', 'Город', 'Индекс', 'Дата', TARGET, 'ID_Контрагента', 'Год', 'Месяц']
    exclude_cols += ['last_sale_date']  # служебная
    features = [c for c in df.columns if c not in exclude_cols]

    last_hist_date = sales['Дата'].max()

    # Фиксированные временные границы
    train_end = '2024-12-31'
    val_start = '2025-01-01'
    val_end = '2025-07-31'
    test_start = '2025-08-01'
    test_end = '2026-12-31'

    # Обучаем и получаем финальную модель (лог-шкала)
    eval_model, final_model, rmse_val, rmse_test = train_and_evaluate(
        df, features, train_end, val_start, val_end, test_start, test_end, last_hist_date
    )

    # Последняя дата реальной продажи по каждому контрагенту
    last_sale_s = compute_last_real_sale_date(df, last_hist_date)

    # Старт прогноза минимум с 2025-08-01
    default_start = (last_hist_date + relativedelta(months=1)).replace(day=1)
    start_date = max(default_start, FORCE_START)

    # Делаем прогноз пошагово, используя final_model
    forecast_df = forecast_with_dynamic_lags(
        df.copy(), final_model, features,
        start_date=start_date,
        months=FORECAST_MONTHS,
        max_lag=12,
        rollings=[3, 6, 12],
        last_sale_s=last_sale_s
    )

    # Гарантируем целочисленный тип в выгрузке
    forecast_df[TARGET] = forecast_df[TARGET].round().clip(lower=0).astype(int)

    agg_forecast = (forecast_df.groupby('Дата')[TARGET].sum().reset_index())

# Сохраняем
    forecast_df.to_csv('forecast_by_pharmacy.csv', index=False)
    agg_forecast.to_csv('forecast_agg_product.csv', index=False)
    joblib.dump(final_model, 'xgb_final_model.joblib')

    logging.info("Готово! Прогноз и модель сохранены.")
    return final_model, forecast_df, agg_forecast


if name == 'main':
    pipeline(
        sales_path='Продажи.csv',
        stock_path='Остатки.csv',
        ms_path='МС.csv',
        dist_path='index_by_pharmacy.csv',
        weather_path='weather.csv',
        discounts_path='discounts.csv',
        longterm_path='10y_monthly_avg.csv'
    )
